{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PeopleandStopMobilenetFullTune.ipynb","provenance":[{"file_id":"1ADRPHlCjGW8WpEWItstw4_DueOkmRqRp","timestamp":1638561014329}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FZpr2Y77tPuR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640825331675,"user_tz":300,"elapsed":22998,"user":{"displayName":"Olina Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03743884351763952227"}},"outputId":"48b2b7fd-650d-467f-f9a0-26a2063b8fcd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"83F7C6MinEZB","executionInfo":{"status":"ok","timestamp":1640825337494,"user_tz":300,"elapsed":4984,"user":{"displayName":"Olina Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03743884351763952227"}}},"source":["import os\n","os.chdir('/content')\n","!tar xpf /content/drive/MyDrive/images.tgz\n","!mv '/content/images' '/content/images_12-3-21'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"DO1GJlxmQHXZ","executionInfo":{"status":"ok","timestamp":1640825337495,"user_tz":300,"elapsed":6,"user":{"displayName":"Olina Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03743884351763952227"}}},"source":["os.chdir('/content/images_12-3-21')\n","os.rename('negative', '0')\n","os.rename('people', '1')\n","os.rename('stopsign', '2')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFb7yYHHtzxa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f8115dd-bf20-4260-92d8-c3c6e39c7cf3","executionInfo":{"status":"ok","timestamp":1640832497678,"user_tz":300,"elapsed":6955151,"user":{"displayName":"Olina Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03743884351763952227"}}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Activation\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import imagenet_utils\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","import os\n","import shutil\n","import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","# Organize data into train, valid, test dirs\n","os.chdir('/content/images_12-3-21')\n","if os.path.isdir('train/0/') is False: \n","  os.mkdir('train')\n","  os.mkdir('valid')\n","\n","  for i in range(0, 3):\n","    shutil.move(f'{i}', 'train')\n","    os.mkdir(f'valid/{i}')\n","\n","    valid_samples = random.sample(os.listdir(f'train/{i}'), 30)\n","    for j in valid_samples:\n","      shutil.move(f'train/{i}/{j}', f'valid/{i}')\n","train_path = '/content/images_12-3-21/train'\n","valid_path = '/content/images_12-3-21/valid'\n","\n","train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=train_path, target_size=(224,224), batch_size=10)\n","valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory=valid_path, target_size=(224,224), batch_size=10)\n","\n","mobile = tf.keras.applications.mobilenet.MobileNet()\n","\n","#x = mobile.layers[-6].output\n","x = mobile.output\n","\n","output = Dense(units=3, activation='softmax')(x)\n","\n","model = Model(inputs=mobile.input, outputs=output)\n","\n","#for layer in model.layers[:-23]:\n","#    layer.trainable = False\n","\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x=train_batches,\n","            steps_per_epoch=len(train_batches),\n","            validation_data=valid_batches,\n","            validation_steps=len(valid_batches),\n","            epochs=80,\n","            verbose=2\n",")\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5512 images belonging to 3 classes.\n","Found 90 images belonging to 3 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n","17227776/17225924 [==============================] - 0s 0us/step\n","17235968/17225924 [==============================] - 0s 0us/step\n","Epoch 1/80\n","552/552 - 106s - loss: 0.9808 - accuracy: 0.9788 - val_loss: 0.9504 - val_accuracy: 0.9889 - 106s/epoch - 192ms/step\n","Epoch 2/80\n","552/552 - 87s - loss: 0.9010 - accuracy: 0.9944 - val_loss: 0.8886 - val_accuracy: 1.0000 - 87s/epoch - 158ms/step\n","Epoch 3/80\n","552/552 - 84s - loss: 0.8395 - accuracy: 0.9922 - val_loss: 0.8393 - val_accuracy: 0.9889 - 84s/epoch - 151ms/step\n","Epoch 4/80\n","552/552 - 87s - loss: 0.7814 - accuracy: 0.9958 - val_loss: 0.7893 - val_accuracy: 0.9889 - 87s/epoch - 158ms/step\n","Epoch 5/80\n","552/552 - 84s - loss: 0.7314 - accuracy: 0.9924 - val_loss: 0.7361 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 6/80\n","552/552 - 83s - loss: 0.6808 - accuracy: 0.9966 - val_loss: 0.6909 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 7/80\n","552/552 - 83s - loss: 0.6357 - accuracy: 0.9966 - val_loss: 0.6564 - val_accuracy: 0.9889 - 83s/epoch - 151ms/step\n","Epoch 8/80\n","552/552 - 84s - loss: 0.5926 - accuracy: 0.9975 - val_loss: 0.6164 - val_accuracy: 0.9889 - 84s/epoch - 152ms/step\n","Epoch 9/80\n","552/552 - 84s - loss: 0.5540 - accuracy: 0.9966 - val_loss: 0.5716 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 10/80\n","552/552 - 83s - loss: 0.5174 - accuracy: 0.9956 - val_loss: 0.5424 - val_accuracy: 0.9889 - 83s/epoch - 151ms/step\n","Epoch 11/80\n","552/552 - 83s - loss: 0.4823 - accuracy: 0.9966 - val_loss: 0.4967 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 12/80\n","552/552 - 84s - loss: 0.4535 - accuracy: 0.9940 - val_loss: 0.4766 - val_accuracy: 0.9889 - 84s/epoch - 151ms/step\n","Epoch 13/80\n","552/552 - 83s - loss: 0.4211 - accuracy: 0.9955 - val_loss: 0.4322 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 14/80\n","552/552 - 83s - loss: 0.3907 - accuracy: 0.9969 - val_loss: 0.4025 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 15/80\n","552/552 - 83s - loss: 0.3626 - accuracy: 0.9975 - val_loss: 0.3893 - val_accuracy: 0.9889 - 83s/epoch - 150ms/step\n","Epoch 16/80\n","552/552 - 84s - loss: 0.3409 - accuracy: 0.9953 - val_loss: 0.3640 - val_accuracy: 0.9889 - 84s/epoch - 153ms/step\n","Epoch 17/80\n","552/552 - 83s - loss: 0.3141 - accuracy: 0.9967 - val_loss: 0.3400 - val_accuracy: 0.9889 - 83s/epoch - 151ms/step\n","Epoch 18/80\n","552/552 - 83s - loss: 0.2935 - accuracy: 0.9960 - val_loss: 0.3146 - val_accuracy: 0.9889 - 83s/epoch - 150ms/step\n","Epoch 19/80\n","552/552 - 84s - loss: 0.2705 - accuracy: 0.9975 - val_loss: 0.2783 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 20/80\n","552/552 - 84s - loss: 0.2496 - accuracy: 0.9985 - val_loss: 0.2577 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 21/80\n","552/552 - 84s - loss: 0.2312 - accuracy: 0.9984 - val_loss: 0.2385 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 22/80\n","552/552 - 83s - loss: 0.2135 - accuracy: 0.9989 - val_loss: 0.2207 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 23/80\n","552/552 - 83s - loss: 0.1982 - accuracy: 0.9987 - val_loss: 0.2043 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 24/80\n","552/552 - 85s - loss: 0.1870 - accuracy: 0.9973 - val_loss: 0.1888 - val_accuracy: 1.0000 - 85s/epoch - 153ms/step\n","Epoch 25/80\n","552/552 - 84s - loss: 0.1726 - accuracy: 0.9975 - val_loss: 0.1989 - val_accuracy: 0.9889 - 84s/epoch - 152ms/step\n","Epoch 26/80\n","552/552 - 83s - loss: 0.1595 - accuracy: 0.9980 - val_loss: 0.1633 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 27/80\n","552/552 - 83s - loss: 0.1504 - accuracy: 0.9971 - val_loss: 0.1754 - val_accuracy: 0.9889 - 83s/epoch - 151ms/step\n","Epoch 28/80\n","552/552 - 85s - loss: 0.1371 - accuracy: 0.9982 - val_loss: 0.1650 - val_accuracy: 0.9889 - 85s/epoch - 153ms/step\n","Epoch 29/80\n","552/552 - 84s - loss: 0.1281 - accuracy: 0.9978 - val_loss: 0.1554 - val_accuracy: 0.9889 - 84s/epoch - 152ms/step\n","Epoch 30/80\n","552/552 - 83s - loss: 0.1207 - accuracy: 0.9973 - val_loss: 0.1467 - val_accuracy: 0.9889 - 83s/epoch - 151ms/step\n","Epoch 31/80\n","552/552 - 83s - loss: 0.1111 - accuracy: 0.9976 - val_loss: 0.1387 - val_accuracy: 0.9889 - 83s/epoch - 150ms/step\n","Epoch 32/80\n","552/552 - 84s - loss: 0.1024 - accuracy: 0.9980 - val_loss: 0.1313 - val_accuracy: 0.9889 - 84s/epoch - 153ms/step\n","Epoch 33/80\n","552/552 - 84s - loss: 0.0960 - accuracy: 0.9976 - val_loss: 0.1246 - val_accuracy: 0.9889 - 84s/epoch - 152ms/step\n","Epoch 34/80\n","552/552 - 83s - loss: 0.0908 - accuracy: 0.9973 - val_loss: 0.0864 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 35/80\n","552/552 - 83s - loss: 0.0808 - accuracy: 0.9987 - val_loss: 0.0798 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 36/80\n","552/552 - 84s - loss: 0.0750 - accuracy: 0.9987 - val_loss: 0.0738 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 37/80\n","552/552 - 84s - loss: 0.0697 - accuracy: 0.9987 - val_loss: 0.0682 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 38/80\n","552/552 - 83s - loss: 0.0665 - accuracy: 0.9982 - val_loss: 0.1014 - val_accuracy: 0.9889 - 83s/epoch - 151ms/step\n","Epoch 39/80\n","552/552 - 83s - loss: 0.0667 - accuracy: 0.9967 - val_loss: 0.0951 - val_accuracy: 0.9889 - 83s/epoch - 151ms/step\n","Epoch 40/80\n","552/552 - 84s - loss: 0.0595 - accuracy: 0.9978 - val_loss: 0.0915 - val_accuracy: 0.9889 - 84s/epoch - 152ms/step\n","Epoch 41/80\n","552/552 - 84s - loss: 0.0545 - accuracy: 0.9982 - val_loss: 0.0641 - val_accuracy: 0.9889 - 84s/epoch - 152ms/step\n","Epoch 42/80\n","552/552 - 83s - loss: 0.0506 - accuracy: 0.9984 - val_loss: 0.0469 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 43/80\n","552/552 - 84s - loss: 0.0464 - accuracy: 0.9987 - val_loss: 0.0435 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 44/80\n","552/552 - 84s - loss: 0.0428 - accuracy: 0.9989 - val_loss: 0.0403 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 45/80\n","552/552 - 84s - loss: 0.0400 - accuracy: 0.9989 - val_loss: 0.0373 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 46/80\n","552/552 - 83s - loss: 0.0393 - accuracy: 0.9985 - val_loss: 0.0346 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 47/80\n","552/552 - 84s - loss: 0.0362 - accuracy: 0.9987 - val_loss: 0.0321 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 48/80\n","552/552 - 84s - loss: 0.0369 - accuracy: 0.9980 - val_loss: 0.0300 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 49/80\n","552/552 - 83s - loss: 0.0372 - accuracy: 0.9971 - val_loss: 0.0380 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 50/80\n","552/552 - 83s - loss: 0.0330 - accuracy: 0.9982 - val_loss: 0.0681 - val_accuracy: 0.9889 - 83s/epoch - 150ms/step\n","Epoch 51/80\n","552/552 - 83s - loss: 0.0288 - accuracy: 0.9987 - val_loss: 0.0340 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 52/80\n","552/552 - 84s - loss: 0.0277 - accuracy: 0.9985 - val_loss: 0.0229 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 53/80\n","552/552 - 85s - loss: 0.0262 - accuracy: 0.9987 - val_loss: 0.0219 - val_accuracy: 1.0000 - 85s/epoch - 153ms/step\n","Epoch 54/80\n","552/552 - 82s - loss: 0.0236 - accuracy: 0.9989 - val_loss: 0.0200 - val_accuracy: 1.0000 - 82s/epoch - 149ms/step\n","Epoch 55/80\n","552/552 - 82s - loss: 0.0223 - accuracy: 0.9989 - val_loss: 0.0187 - val_accuracy: 1.0000 - 82s/epoch - 149ms/step\n","Epoch 56/80\n","552/552 - 84s - loss: 0.0236 - accuracy: 0.9982 - val_loss: 0.0176 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 57/80\n","552/552 - 83s - loss: 0.0212 - accuracy: 0.9985 - val_loss: 0.0165 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 58/80\n","552/552 - 83s - loss: 0.0213 - accuracy: 0.9985 - val_loss: 0.0252 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 59/80\n","552/552 - 83s - loss: 0.0185 - accuracy: 0.9987 - val_loss: 0.0146 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 60/80\n","552/552 - 84s - loss: 0.0224 - accuracy: 0.9976 - val_loss: 0.0233 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 61/80\n","552/552 - 84s - loss: 0.0180 - accuracy: 0.9985 - val_loss: 0.0225 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 62/80\n","552/552 - 83s - loss: 0.0162 - accuracy: 0.9989 - val_loss: 0.0218 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 63/80\n","552/552 - 83s - loss: 0.0160 - accuracy: 0.9987 - val_loss: 0.0116 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 64/80\n","552/552 - 84s - loss: 0.0148 - accuracy: 0.9989 - val_loss: 0.0110 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 65/80\n","552/552 - 84s - loss: 0.0154 - accuracy: 0.9987 - val_loss: 0.0103 - val_accuracy: 1.0000 - 84s/epoch - 151ms/step\n","Epoch 66/80\n","552/552 - 83s - loss: 0.0150 - accuracy: 0.9989 - val_loss: 0.0098 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 67/80\n","552/552 - 83s - loss: 0.0145 - accuracy: 0.9989 - val_loss: 0.0093 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 68/80\n","552/552 - 84s - loss: 0.0141 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 69/80\n","552/552 - 84s - loss: 0.0139 - accuracy: 0.9989 - val_loss: 0.0085 - val_accuracy: 1.0000 - 84s/epoch - 151ms/step\n","Epoch 70/80\n","552/552 - 83s - loss: 0.0135 - accuracy: 0.9989 - val_loss: 0.0081 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 71/80\n","552/552 - 83s - loss: 0.0132 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 72/80\n","552/552 - 84s - loss: 0.0129 - accuracy: 0.9989 - val_loss: 0.0073 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 73/80\n","552/552 - 84s - loss: 0.0126 - accuracy: 0.9989 - val_loss: 0.0070 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 74/80\n","552/552 - 83s - loss: 0.0123 - accuracy: 0.9989 - val_loss: 0.0066 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 75/80\n","552/552 - 83s - loss: 0.0121 - accuracy: 0.9989 - val_loss: 0.0063 - val_accuracy: 1.0000 - 83s/epoch - 151ms/step\n","Epoch 76/80\n","552/552 - 84s - loss: 0.0118 - accuracy: 0.9989 - val_loss: 0.0060 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n","Epoch 77/80\n","552/552 - 84s - loss: 0.0210 - accuracy: 0.9973 - val_loss: 0.0059 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 78/80\n","552/552 - 83s - loss: 0.0197 - accuracy: 0.9975 - val_loss: 0.0058 - val_accuracy: 1.0000 - 83s/epoch - 150ms/step\n","Epoch 79/80\n","552/552 - 84s - loss: 0.0136 - accuracy: 0.9985 - val_loss: 0.0056 - val_accuracy: 1.0000 - 84s/epoch - 152ms/step\n","Epoch 80/80\n","552/552 - 84s - loss: 0.0127 - accuracy: 0.9985 - val_loss: 0.0055 - val_accuracy: 1.0000 - 84s/epoch - 153ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fb678041b10>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/peoplestop_dec_mobilenet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vnV0fvZq0xeE","executionInfo":{"status":"ok","timestamp":1640832514158,"user_tz":300,"elapsed":15385,"user":{"displayName":"Olina Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03743884351763952227"}},"outputId":"c3c71ab4-c3d0-4b4f-8487-3ff133c7ce9e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/peoplestop_dec_mobilenet/assets\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfJZ_vgkOWPX","executionInfo":{"status":"ok","timestamp":1640832538534,"user_tz":300,"elapsed":24380,"user":{"displayName":"Olina Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03743884351763952227"}},"outputId":"6581d8af-084d-4971-d062-a5c4cc53a0e9"},"source":["model.save('/content/peoplestop_dec_mobilenet', save_format='tf')\n","# Converting a SavedModel to a TensorFlow Lite model.\n","converter = tf.lite.TFLiteConverter.from_saved_model('/content/peoplestop_dec_mobilenet')\n","tflite_model = converter.convert()\n","open(\"/content/peoplestop_dec_mobilenet.tflite\", \"wb\").write(tflite_model)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/peoplestop_dec_mobilenet/assets\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["16913436"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"reyGqWhXQbug"},"source":["!mv /content/peoplestop_dec_mobilenet.tflite /content/drive/MyDrive/peoplestop_dec_mobilenet4.tflite"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"W_mA3PXksenk","executionInfo":{"status":"error","timestamp":1639863479517,"user_tz":300,"elapsed":1308,"user":{"displayName":"Olina Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03743884351763952227"}},"outputId":"2d77bce1-6c25-479f-eb65-0d43ce5be8e9"},"source":["import cv2\n","from keras.preprocessing.image import img_to_array\n","img = cv2.imread('/content/images_12-3-21/valid/1/0-2576.jpg')\n","re = cv2.resize(img, (224,224))\n","print(re.shape)\n","re = img_to_array(re)\n","re = np.expand_dims(re, axis=0)\n","print(re.shape)\n","x = model.predict(re)\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-1e587046f548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/images_12-3-21/valid/1/0-2576.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"]}]}]}
